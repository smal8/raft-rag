{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82PKC1PrewDX"
      },
      "outputs": [],
      "source": [
        "# ollama installation from: https://medium.com/@abonia/running-ollama-in-google-colab-free-tier-545609258453\n",
        "# faiss usage from: https://python.langchain.com/docs/integrations/vectorstores/faiss/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOTG71bfbchg"
      },
      "outputs": [],
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "BgRV9D9aH9g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMjpmoqCZxR6"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ASpVqeZRrO"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-community faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "b53kywJERMa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaiMtKUUegym"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nvK8GsEYrZt"
      },
      "outputs": [],
      "source": [
        "os.environ['OLLAMA_HOST'] = '127.0.0.1:11434'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1mV_Ik5ZHvx"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-NOSR1GZLNY"
      },
      "outputs": [],
      "source": [
        "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "\n",
        "vector_store = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/index_faiss\", embeddings, allow_dangerous_deserialization=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPDN127Pfkdk"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 1, \"score_threshold\" : 0.2})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model = PeftModel.from_pretrained(AutoModelForCausalLM.from_pretrained('facebook/opt-1.3b'), 'new_model')\n",
        "baseline = AutoModelForCausalLM.from_pretrained('facebook/opt-1.3b')"
      ],
      "metadata": {
        "id": "xyNKJDe0jTyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-1.3b')"
      ],
      "metadata": {
        "id": "DuvD-2Dtj2fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Where is Atlanta?\"\n",
        "\n",
        "text = question + retriever.invoke(question)[0].dict()['page_content']\n",
        "\n",
        "print(retriever.invoke(question)[0].dict()['page_content'])\n",
        "tokenized = tokenizer(text, return_tensors='pt', padding=True)\n",
        "output =  finetuned_model.generate(tokenized.input_ids, max_new_tokens = 100) # Can update with either baseline or finetuned_model\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "tqCZWdO2kbG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}