{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Llava Inference code from: https://huggingface.co/llava-hf/llava-1.5-13b-hf"
      ],
      "metadata": {
        "id": "nQTS0zvWQOEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "\n",
        "import json\n",
        "\n",
        "model_id = \"llava-hf/llava-1.5-13b-hf\"\n",
        "\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        ").to('cuda')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Em5pbcCRtbri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\n",
        "\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "          {\"type\": \"text\", \"text\": \"Please summarize the image in a detailed manner\"},\n",
        "          {\"type\": \"image\"},\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n"
      ],
      "metadata": {
        "id": "F_9F-le4tljX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F55BNJzh2E1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir('/content/drive/MyDrive/final_dataset_images/final_dataset_images')"
      ],
      "metadata": {
        "id": "g3-FZFWwTq_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = []\n",
        "\n",
        "for path in files:\n",
        "  image = Image.open('/content/drive/MyDrive/final_dataset_images/final_dataset_images/' + path)\n",
        "  inputs = processor(images=image, text=prompt, return_tensors='pt').to('cuda', torch.float16)\n",
        "  output = model.generate(**inputs, max_new_tokens=100000, do_sample=False)\n",
        "  begin_text_prompt_length = len(\"USER:   Please summarize the image in a detailed manner ASSISTANT: \")\n",
        "  response = processor.decode(output[0], skip_special_tokens=True)[begin_text_prompt_length:]\n",
        "  json_obj = {}\n",
        "  json_obj['path'] =  path\n",
        "  json_obj['summary'] = response\n",
        "  summaries.append(json_obj)"
      ],
      "metadata": {
        "id": "U1lDVXONmWw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('image_summaries.json', 'w') as image_file:\n",
        "  json.dump(summaries, image_file)"
      ],
      "metadata": {
        "id": "3og458jVTh94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}