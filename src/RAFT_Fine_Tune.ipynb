{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate peft bitsandbytes transformers trl"
      ],
      "metadata": {
        "id": "B7gn3MG6aNav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8qeG5I8GmtP"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"json\", data_files=\"output.completion.jsonl\", split=\"train\")\n",
        "print(data[0])"
      ],
      "metadata": {
        "id": "qawnB8ZCGHOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type='nf4',\n",
        "                         bnb_4bit_compute_dtype='float16', bnb_4bit_use_double_quant=False)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained('facebook/opt-1.3b',\n",
        "                                             quantization_config=bnb,\n",
        "                                             device_map={\"\":0})\n",
        "\n",
        "model.config.use_cache=False\n",
        "model.config.pretraining_tp=1"
      ],
      "metadata": {
        "id": "ZFwixT9lI4mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-1.3b', trust_remote_code=True,\n",
        "                                          use_fast=True)\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "\n",
        "def preprocess(line):\n",
        "    line['text'] = f\"Prompt: {line['prompt']} --- Completion: {line['completion']}\"\n",
        "    del line['prompt'], line['completion']\n",
        "    return line\n",
        "\n",
        "data = data.map(preprocess)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "Aieq-jQmGZwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loraconfig = LoraConfig(lora_alpha=0.5, lora_dropout=0.1, r=16,\n",
        "                        target_modules=['k_proj', 'v_proj', 'q_proj'], task_type='CAUSAL_LM', bias='none')"
      ],
      "metadata": {
        "id": "AUtEsnPxLnpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loramodel = get_peft_model(model, loraconfig)"
      ],
      "metadata": {
        "id": "JPtBvOV9S85d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_args = TrainingArguments(output_dir='.',\n",
        "                               num_train_epochs=1,\n",
        "                               per_device_train_batch_size=2,\n",
        "                               gradient_accumulation_steps=1,\n",
        "                               optim='adamw_torch',\n",
        "                               save_steps=0,\n",
        "                               logging_steps=10,\n",
        "                               learning_rate=0.03,\n",
        "                               weight_decay=0.001,\n",
        "                               fp16=False,\n",
        "                               bf16=False,\n",
        "                               max_grad_norm=0.3,\n",
        "                               max_steps=-1,\n",
        "                               warmup_ratio=0.3,\n",
        "                               group_by_length=True,\n",
        "                               lr_scheduler_type='cosine',\n",
        "                               report_to='none')"
      ],
      "metadata": {
        "id": "Qg9olOjlUuzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(model=loramodel,\n",
        "                     train_dataset=data,\n",
        "                     tokenizer=tokenizer,\n",
        "                     args=train_args)"
      ],
      "metadata": {
        "id": "_-3TJaNgWzM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "TeKoo55vX0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained('new_model')\n",
        "\n",
        "baseline = AutoModelForCausalLM.from_pretrained('facebook/opt-1.3b')\n",
        "#finetuned = PeftModel.from_pretrained(baseline, 'new_model')\n",
        "#finetuned = finetuned.merge_and_unload()\n",
        "finetuned_model = PeftModel.from_pretrained(AutoModelForCausalLM.from_pretrained('facebook/opt-1.3b'), 'new_model')\n",
        "#finetuned.save_pretrained('.')"
      ],
      "metadata": {
        "id": "NJcmep_9YtX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(baseline.config)"
      ],
      "metadata": {
        "id": "JJ4cF0yJMJ-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-1.3b')"
      ],
      "metadata": {
        "id": "M1A0rnshFlKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text='Where is Atlanta?'\n",
        "tokenized = tokenizer(text, return_tensors='pt', padding=True)\n",
        "output = finetuned_model.generate(tokenized.input_ids)\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "TB93DcWpIGrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model, trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MsxBFiCnX6LQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}